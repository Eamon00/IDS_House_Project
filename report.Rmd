---
title: "Predicting House Prices"
author: "by JIFEM: Joe, Eamon, Innes, Freddie & Mat"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load-lib, include = FALSE}
library(tidyverse)
library(readr)
library(ggplot2)
library(corrplot)
library(dplyr)
library(purrr)

```


```{r load-data, include=FALSE}
library(readr)
library(ggplot2)
train <- read_csv("data/train.csv")

data_important <- test[ , c(1, 3)]
head(data_important)

head(house_prices_sel)

# Loading librarys
library(readr)
library(dplyr)
library(ggplot2)
library(corrplot)

# Read data
house_prices <- read_csv("data/train.csv")

#Cleaned data (Same as projecy)
house_prices_filtered <- house_prices %>% 
  mutate(TotalBath = BsmtFullBath + 
           BsmtHalfBath + 
           HalfBath + 
           FullBath)


qual_map <- c("Ex" = 5,
              "Gd" = 4,
              "TA" = 3,
              "Fa" = 2,
              "Po" = 1)

pave_map <- c("Y" = 2,
              "N"= 0,
              "P"= 1)

electric_map <- c("SBrkr" = 5,
                  "FuseA" = 4,
                  "FuseF" = 3,
                  "FuseP" = 2,
                  "Mix" = 1)

building_map <- c("1Fam"   = 5,
                  "TwnhsE" = 4,
                  "Twnhs"  = 3,
                  "Duplex" = 2,
                  "2fmCon" = 1,
                  "Other"  = 0)


# Apply mapping
house_prices_filtered$KitchenQual <- qual_map[house_prices_filtered$KitchenQual]
house_prices_filtered$ExterQual <- qual_map[house_prices_filtered$ExterQual]
house_prices_filtered$HeatingQC <- qual_map[house_prices_filtered$HeatingQC]
house_prices_filtered$HeatingQC <- qual_map[house_prices_filtered$HeatingQC]
house_prices_filtered$PavedDrive <- pave_map[house_prices_filtered$PavedDrive]
house_prices_filtered$Electrical <- electric_map[house_prices_filtered$Electrical]
house_prices_filtered$BldgType <- building_map[house_prices_filtered$BldgType]



# Creating Heatmap

##Holding only numeric
numeric_vars <- house_prices_filtered[, sapply(house_prices_filtered, is.numeric)]


#Plot heatmap using Corr package
price_corr <- cor(numeric_vars, use = "complete.obs")[, "SalePrice"]

price_corr_df <- data.frame(
  variable = names(price_corr),
  correlation = as.numeric(price_corr)
) %>%
  arrange(desc(correlation)) 



#Nice little graph
library(ggplot2)

ggplot(price_corr_df, aes(x = reorder(variable, correlation), y = correlation)) +
  geom_col(fill = "steelblue") + 
  coord_flip() +                   
  theme_minimal() +                
  labs(
    title = "Variables Positively Correlated with Price",
    x = "Variable",
    y = "Correlation"
  )

#Filtered for > something

Price_corr_filtered <- price_corr_df %>%
  filter(correlation > 0.15) 

#Nice little graph
library(ggplot2)

ggplot(Price_corr_filtered, aes(x = reorder(variable, correlation), y = correlation)) +
  geom_col(fill = "steelblue") + 
  coord_flip() +                   
  theme_minimal() +                
  labs(
    title = "Variables Positively Correlated with Price",
    x = "Variable",
    y = "Correlation"
  )
```


## Introduction

We set out to investigate how accurately house prices can be predicted using a range of explanatory variables from the Ames Housing dataset. Compiled by Dean De Cock, this dataset provides detailed information on residential properties sold in Ames, Iowa between 2006 and 2010. Our goal was to explore which features—such as structural characteristics, location factors, and indicators of property condition—carry the most predictive power, and to evaluate how effectively different modelling approaches can estimate a home’s final sale price. By analysing these variables and building predictive models, we aimed to determine not only the achievable accuracy of house price predictions, but also which aspects of a home contribute most strongly to its market value.

citation - 
See http://libraryguides.vu.edu.au/c.php?g=386501&p=4347840 for guidance on proper citation for datasets. 
If you got your data off the web, make sure to state the retrieval date.


## Methods

# Data Cleaning and Preprocessing

Our first step in data cleaning was to create a more useful representation of bathroom-related variables. Instead of working with separate fields—BsmtHalfBath, BsmtFullBath, HalfBath, and FullBath—we combined them into a single variable, TotalBath, representing the total number of bathrooms in each house. This made comparisons across properties more intuitive and improved the convenience of downstream analysis.

We also transformed the KitchenQual variable from categorical descriptions of quality into a numerical rating scale from 1 to 5, where 5 represents the highest quality and 1 the lowest. This conversion made the variable easier to interpret and more convenient to use in modelling functions. We applied the same approach to ExterQual, using the same qual_map transformation because both variables used identical categorical descriptors.

In addition, all NA values in the PoolArea variable were converted to 0. Rather than implying missing data, NA in this context simply indicates that the house does not have a pool. Treating these as zeros prevented the presence of missing values from complicating numeric functions or producing unexpected results during analysis.

# Data Analysis

To familiarise ourselves with the dataset, we began by producing several exploratory graphs. For example, we plotted the distribution of sale prices to ensure there was sufficient variation to support meaningful prediction.

```{r}
ggplot(house_prices_sel, aes(x = SalePrice)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  labs(title = "Distribution of House Prices")
```


Because the original dataset contained over 80 variables, we then aimed to reduce dimensionality and avoid unnecessary noise. Initially, we selected variables based on intuition and visual inspection—choosing features we believed would be strongly correlated with sale price. However, we quickly realised that a more systematic approach would be more efficient. We generated a correlation heatmap for all numerical variables and identified the 17 features with the highest correlations to the target variable. These variables formed the basis for our subsequent modelling work.











## Findings

The write-up of your project and findings go here. 

Think of this as the text of your presentation with some extra detail to cover what there was not time to discuss in the presentation. This might include any assumptions you made when doing your analysis, any limitations of the work you have done or any ideas you have for future work. Feel free to split this section into subsections to make it easier to read. 

The length should be roughly 1,500 words. 
If you want to use a word count addin, you can install this by copying and pasting the following into RStudio:

`devtools::install_github("benmarwick/wordcountaddin", type = "source", dependencies = TRUE)`

You will then need to restart RStudio. Once you have done that, select the text you want to count the words of, go to Addins, and select the `Word count` addin.
This addin counts words using two different algorithms, but the results should be similar and as long as you're in the ballpark of 1,500 words, you're good! 
The addin will ignore code chunks and only count the words in prose. If you don't want to use the addin you can always copy and paste the text into Microsoft Word to do a Word Count!

You can also load your data here and present any analysis results / plots.
Make sure to hide your code with  `echo = FALSE` unless the point you are trying to make is about the code itself, in which case you should show your code.










# DATA ANALYSIS

# INITIAL FINDINGS (including graphs)

# MODEL + MODELLING METHODS

# FINAL DISCUSSION



## References

List any references here. You should, at a minimum, list your data source.


