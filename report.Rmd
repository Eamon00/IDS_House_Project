---
title: "Predicting House Prices"
author: "by JIFEM: Joe, Eamon, Innes, Freddie & Mat"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load-lib, include = FALSE}
library(tidyverse)
library(readr)
library(ggplot2)
library(corrplot)
library(dplyr)
library(purrr)

```


```{r load-data, include=FALSE}

house_prices <- read_csv("data/train.csv")

house_prices_filtered <- house_prices %>% 
  mutate(TotalBath = BsmtFullBath + 
           BsmtHalfBath + 
           HalfBath + 
           FullBath)


qual_map <- c("Ex" = 5,
              "Gd" = 4,
              "TA" = 3,
              "Fa" = 2,
              "Po" = 1)

pave_map <- c("Y" = 2,
              "N"= 0,
              "P"= 1)

electric_map <- c("SBrkr" = 5,
                  "FuseA" = 4,
                  "FuseF" = 3,
                  "FuseP" = 2,
                  "Mix" = 1)

building_map <- c("1Fam"   = 5,
                  "TwnhsE" = 4,
                  "Twnhs"  = 3,
                  "Duplex" = 2,
                  "2fmCon" = 1,
                  "Other"  = 0)


# Apply mapping
house_prices_filtered$KitchenQual <- qual_map[house_prices_filtered$KitchenQual]
house_prices_filtered$ExterQual <- qual_map[house_prices_filtered$ExterQual]
house_prices_filtered$HeatingQC <- qual_map[house_prices_filtered$HeatingQC]
house_prices_filtered$HeatingQC <- qual_map[house_prices_filtered$HeatingQC]
house_prices_filtered$PavedDrive <- pave_map[house_prices_filtered$PavedDrive]
house_prices_filtered$Electrical <- electric_map[house_prices_filtered$Electrical]
house_prices_filtered$BldgType <- building_map[house_prices_filtered$BldgType]

numeric_vars <- house_prices_filtered[, sapply(house_prices_filtered, is.numeric)]

price_corr <- cor(numeric_vars, use = "complete.obs")[, "SalePrice"]

price_corr_df <- data.frame(
  variable = names(price_corr),
  correlation = as.numeric(price_corr)
) %>%
  arrange(desc(correlation)) 

Price_corr_filtered <- price_corr_df %>%
  filter(correlation > 0.15) 

theme_house <- theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 15),
    axis.title = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = "white", colour = NA)
  )

main_colour <- "#3B82F6"   
accent_colour <- "#1E40AF" 
```


# Introduction

Our objective is to accurately predict house sale prices using a comprehensive set of explanatory variables from the Ames Housing dataset. Compiled by Dean De Cock, this dataset provides detailed information on residential properties sold in Ames, Iowa, between 2006 and 2010. The dataset is divided into training and testing sets, each containing the sale price for each property along with numerous features such as neighborhood, number of bathrooms and overall quality which can all be used to predict the properties sale price.

The goal of our investigation is to produce a model which can successfully predict the sale price of properties in the testing data set. We also aim to identify the variables which have the greatest predictive power for sale price.

Kaggle.com. (2016). House Prices: Advanced Regression Techniques | Kaggle. [online] Retrieved November 1, 2025, from https://www.kaggle.com/c/house-prices-advanced-regression-techniques.


# Methods

## Data Cleaning and Preprocessing

Before building our predictive model, we first performed data cleaning and preprocessing to ensure the dataset was suitable for analysis.

Our first step was to create a more useful representation of bathroom-related variables. Rather than treating — BsmtHalfBath, BsmtFullBath, HalfBath, and FullBath — as seperate variables; we combined them into a single variable, TotalBath, representing the total number of bathrooms in each house. This made comparisons across properties simpler as the dataset was more intuitive and simpler to model.

We also transformed the KitchenQual variable from categorical descriptions of quality into a numerical rating scale from 1 to 5, where 5 represents the highest quality and 1 the lowest. This conversion made the variable easier to interpret and more convenient to use in modelling functions. We applied the same approach to ExterQual, using the same qual_map transformation because both variables used identical categorical descriptors.

In addition, all NA values in the PoolArea variable were converted to 0. Rather than implying missing data, NA in this context simply indicates that the house does not have a pool. Treating these as zeros prevented the presence of missing values from complicating numeric functions or producing unexpected results during analysis.

We did not remove any outliers in terms of house price, under the assumption that the selected explanatory variables would be able to account for the full range of property values.

## Data Analysis

To familiarize ourselves with the dataset, we began by producing several exploratory graphs. For example, we plotted the distribution of sale prices to ensure there was sufficient variation to support meaningful prediction. 

We observed a roughly bell shaped distribution centred around $180,000. Although there was sufficient variation in house prices to allow for meaningful prediction, the high value of right skew could cause issues when modeling higher house prices due to the limited number of data points.

## Figure 1.1 - Distribution of house prices
```{r, echo=FALSE}
ggplot(house_prices_filtered, aes(x = SalePrice/1000)) +
  geom_histogram(
    bins = 30,
    fill = main_colour,
    color = accent_colour
  ) +
  labs(title = NULL,
       x = "Sale Price (Thousands of $)",
       y = "Count") +
  theme_house
```

The original dataset contained over 80 variables which introduced unnecessary noise and risked over fitting. Therefore, we chose to reduce the number of variables down to 17. Initially, we selected variables based on intuition and visual inspection—choosing features we believed would be strongly correlated with sale price. However, we quickly realised that a more systematic approach would be more efficient. We generated a correlation heatmap for all numerical variables and identified the 17 features with the highest correlations to the target variable. These variables formed the basis for our subsequent modelling work.

## Figure 1.2 - Variables correlation with Sale Price

```{r, echo=FALSE}
ggplot(Price_corr_filtered,
       aes(x = reorder(variable, correlation), y = correlation)) +
  geom_col(fill = main_colour, color = accent_colour) +
  coord_flip() +
  labs(
    title = NULL,
    x = "Variable",
    y = "Correlation"
  ) + theme_house +
  theme(
  axis.text.y = element_text(size = 6),
  plot.title = element_blank()
)
```


Using this heat map, we condensed our number of variables down to 17, by selecting a variety of unique variables which showed strong correlation with sale price. We then decided to run the model on every variation of 12 variables, selecting the one that had the highest R squared score. This allowed us to systematically reduce the number of variables down further, to only the variables with the highest prediciting power. We used a linear regression model, as its ouput is far more suitable for the data type than a logistic regression model, which is better for binary outputs.

```{r}
library(ggplot2)
library(readr)

# Load the data
df <- read_csv("data/train.csv")

ggplot(df, aes(x = OverallCond, y = SalePrice / 1000)) +
  geom_jitter(alpha = 0.5, width = 0.2) +
  geom_smooth(method = "lm", se = TRUE, color = "blue") + 
  labs(
    title = "Sale Price vs Overall Condition",
    x = "Overall Condition (1 = Poor, 10 = Excellent)",
    y = "Sale Price (Thousands of $)"
  ) +
  theme_house



```




The write-up of your project and findings go here. 

Think of this as the text of your presentation with some extra detail to cover what there was not time to discuss in the presentation. This might include any assumptions you made when doing your analysis, any limitations of the work you have done or any ideas you have for future work. Feel free to split this section into subsections to make it easier to read. 

The length should be roughly 1,500 words. 
If you want to use a word count addin, you can install this by copying and pasting the following into RStudio:

`devtools::install_github("benmarwick/wordcountaddin", type = "source", dependencies = TRUE)`

You will then need to restart RStudio. Once you have done that, select the text you want to count the words of, go to Addins, and select the `Word count` addin.
This addin counts words using two different algorithms, but the results should be similar and as long as you're in the ballpark of 1,500 words, you're good! 
The addin will ignore code chunks and only count the words in prose. If you don't want to use the addin you can always copy and paste the text into Microsoft Word to do a Word Count!

You can also load your data here and present any analysis results / plots.
Make sure to hide your code with  `echo = FALSE` unless the point you are trying to make is about the code itself, in which case you should show your code.











# INITIAL FINDINGS (including graphs)

# MODEL + MODELLING METHODS

# FINAL DISCUSSION

Through our findings, we are able to conclude that a small number of key housing attributes play a major role in shaping sale prices in Ames. Variables such as OverallQual, GrLivArea, GarageCars, and YearBuilt consistently showed the strongest relationships with SalePrice during our exploratory analysis. Using these predictors, we were able to fit a linear regression model that captured the main pricing trends reasonably well, achieving a moderate R² and producing predicted prices that aligned closely with the actual values for much of the dataset. However, the residual patterns indicated that a simple linear approach cannot fully represent the more complex, non-linear interactions present in the housing market. It is important to acknowledge the assumptions and limitations of our investigation. We treated missing values and categorical variables using simplified imputation and encoding approaches, and these choices may overlook subtle structure in the data. Our models also assume linearity and independence between predictors, which is unlikely to hold in real housing markets. While our model performed reliably on the selected predictors, more advanced techniques or additional feature engineering would likely produce stronger results. However, this model was made specifically for a very small part of the housing market, specific to Ames, Iowa. This means in the grand scheme of things this model may perform as well on a more generalised housing market in terms of a more wide scale range of places. Ethically, we recognise that our findings do not incorporate broader socio-economic or neighbourhood-level influences that affect real estate valuation. Oversimplifying model outputs or applying them outside the context of this dataset could lead to misleading conclusions, as housing markets are shaped by many external factors not represented here. 

## References

List any references here. You should, at a minimum, list your data source.


